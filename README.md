# ğŸ›’ BuyScraper - EconomÃ­a en tiempo real

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)](tests/)

Scraper genÃ©rico y Ã©tico de precios de productos en lÃ­nea con anÃ¡lisis temporal. VersiÃ³n 2.0 con mejoras profesionales de robustez y compliance.

## âœ¨ CaracterÃ­sticas

### ğŸ” Scraping Ã‰tico y Robusto

- âœ… **Respeto a robots.txt**: VerificaciÃ³n automÃ¡tica antes de cada scraping
- âœ… **Rate limiting**: Control de requests por dominio para evitar sobrecargar servidores
- âœ… **Retry logic**: Reintentos automÃ¡ticos con backoff exponencial
- âœ… **Logging profesional**: Sistema de logs con rotaciÃ³n automÃ¡tica

### ğŸ¯ Funcionalidad Core

- âœ… **Scraping genÃ©rico**: ConfiguraciÃ³n vÃ­a selectores CSS
- âœ… **Multi-sitio**: Procesa mÃºltiples sitios desde archivo YAML
- âœ… **Parsing robusto**: Maneja formatos de precio US y EU
- âœ… **AnÃ¡lisis temporal**: Notebook Jupyter con visualizaciones

## ğŸ“¦ Requisitos

```bash
Python 3.8+
```

## ğŸš€ InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar repositorio
git clone https://github.com/Medalcode/BuyScraper.git
cd BuyScraper

# 2. Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Ejecutar
python src/scraper/scrape.py --sites config/sites.yaml --output data/prices.csv
```

## ğŸ® Uso

### Modo 1: MÃºltiples Sitios (ConfiguraciÃ³n YAML)

```bash
python src/scraper/scrape.py --sites config/sites.yaml --output data/prices.csv
```

**ConfiguraciÃ³n (`config/sites.yaml`):**

```yaml
sites:
  - url: "https://ejemplo.com/producto"
    price_selector: ".price"
    name_selector: ".product-title"
    product: "Nombre del Producto"
    currency: "ARS"
```

### Modo 2: URL Ãšnica (Ad-hoc)

```bash
python src/scraper/scrape.py \
  --url "https://ejemplo.com/producto" \
  --selector ".price" \
  --product "Mi Producto" \
  --output data/prices.csv
```

### Modo 3: AnÃ¡lisis de Datos

```bash
jupyter notebook notebooks/analysis.ipynb
```

## ğŸ“Š Formato de Datos

Los datos se guardan en CSV con el siguiente esquema:

```csv
timestamp,site,product,price,currency,url
2025-12-25T14:00:00,https://ejemplo.com,Producto X,1999.99,ARS,https://ejemplo.com/producto
```

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Con coverage
pytest --cov=src --cov-report=html

# Test especÃ­fico
pytest tests/test_parse_price.py -v
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Logging

Los logs se guardan automÃ¡ticamente en `logs/scraper_YYYYMMDD.log`:

```python
from src.scraper import setup_logger

logger = setup_logger(
    name='buyscraper',
    console_level=logging.INFO,
    file_level=logging.DEBUG
)
```

### Rate Limiting

ConfiguraciÃ³n global en `scrape.py`:

```python
rate_limiter = RateLimiter(
    requests_per_minute=10,  # 10 requests por minuto
    global_delay=1.0          # 1 segundo entre requests
)
```

### Retry Logic

ConfiguraciÃ³n de reintentos:

```python
retry_handler = RetryHandler(
    max_retries=3,         # 3 reintentos
    backoff_factor=2.0,    # Backoff exponencial (1s, 2s, 4s)
    initial_delay=1.0      # Delay inicial
)
```

## ğŸ—ï¸ Estructura del Proyecto

```
BuyScraper/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ scraper/
â”‚       â”œâ”€â”€ __init__.py       # MÃ³dulo principal
â”‚       â”œâ”€â”€ scrape.py         # Script de scraping
â”‚       â”œâ”€â”€ logger.py         # Sistema de logging
â”‚       â”œâ”€â”€ robots.py         # Verificador de robots.txt
â”‚       â”œâ”€â”€ ratelimit.py      # Rate limiter
â”‚       â””â”€â”€ retry.py          # Retry logic
â”œâ”€â”€ config/
â”‚   â””â”€â”€ sites.yaml            # ConfiguraciÃ³n de sitios
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_prices.csv     # Datos de ejemplo
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb        # AnÃ¡lisis y visualizaciones
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_parse_price.py   # Tests de parsing
â”‚   â”œâ”€â”€ test_logger.py        # Tests de logging
â”‚   â””â”€â”€ test_ratelimit.py     # Tests de rate limiting
â”œâ”€â”€ logs/                     # Logs (auto-generado)
â”œâ”€â”€ requirements.txt          # Dependencias
â”œâ”€â”€ .gitignore               # Git ignore
â””â”€â”€ README.md                # Este archivo
```

## ğŸ“š DocumentaciÃ³n Adicional

- **[Reporte de Estado](REPORTE_DESARROLLO.md)**: Estado completo del desarrollo
- **[Mejoras Priorizadas](MEJORAS_PRIORIZADAS.md)**: Roadmap de mejoras futuras
- **[Notebook de AnÃ¡lisis](notebooks/analysis.ipynb)**: Ejemplos de visualizaciÃ³n

## ğŸ¯ Casos de Uso

### 1. Monitoreo de Competencia

```bash
# Configurar sitios competidores en sites.yaml
# Programar con cron para ejecuciÃ³n diaria
0 2 * * * cd /path/to/BuyScraper && python src/scraper/scrape.py --sites config/sites.yaml
```

### 2. DetecciÃ³n de Ofertas

```python
# Analizar histÃ³rico y comprar cuando precio < promedio
import pandas as pd

df = pd.read_csv('data/prices.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])

product_df = df[df['product'] == 'Mi Producto']
avg_price = product_df['price'].mean()
current_price = product_df.iloc[-1]['price']

if current_price < avg_price * 0.9:
    print("Â¡Buen momento para comprar!")
```

### 3. AnÃ¡lisis de Mercado

```bash
# Recolectar datos por semanas/meses
# Analizar tendencias en notebook
jupyter notebook notebooks/analysis.ipynb
```

## âš ï¸ Consideraciones Legales

### âš–ï¸ Uso Responsable

Este scraper incluye protecciones Ã©ticas:

1. **robots.txt**: Verifica automÃ¡ticamente permisos antes de scrapear
2. **Rate limiting**: Evita sobrecargar servidores
3. **User-Agent honesto**: Identifica como navegador estÃ¡ndar
4. **Delays configurables**: Respeta polÃ­ticas de los sitios

### ğŸ“œ Responsabilidad del Usuario

- âœ… Verifica que el scraping estÃ¡ permitido por tÃ©rminos de servicio
- âœ… Usa delays razonables entre requests
- âœ… No uses para fines comerciales sin permiso
- âœ… Respeta la privacidad y propiedad intelectual

## ğŸ› Troubleshooting

### Error: `ImportError: No module named 'bs4'`

```bash
pip install beautifulsoup4
```

### Error: `robots.txt disallows scraping`

```python
# Usar respect_robots=False solo si estÃ¡s seguro
python src/scraper/scrape.py --url "..." --selector "..." # Usa robots.txt por defecto
```

### Error: Selector CSS no encuentra precio

```bash
# 1. Inspeccionar pÃ¡gina con DevTools (F12)
# 2. Usar Inspector para encontrar elemento
# 3. Copiar selector CSS correcto
# 4. Actualizar sites.yaml
```

## ğŸ“ˆ Changelog

### v2.0.0 (2025-12-25) - Sprint 1 Complete

- âœ… Sistema de logging profesional con rotaciÃ³n
- âœ… VerificaciÃ³n automÃ¡tica de robots.txt
- âœ… Rate limiting por dominio y global
- âœ… Retry logic con backoff exponencial
- âœ… Tests unitarios expandidos
- âœ… DocumentaciÃ³n mejorada

### v1.0.0 (2025-10-01) - Initial Release

- âœ… Scraper genÃ©rico con selectores CSS
- âœ… ConfiguraciÃ³n multi-sitio vÃ­a YAML
- âœ… Parsing robusto de precios
- âœ… Notebook de anÃ¡lisis
- âœ… Tests unitarios bÃ¡sicos

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas:

1. Fork el repositorio
2. Crear feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a branch (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ‘¤ Autor

**Medalcode**

- GitHub: [@Medalcode](https://github.com/Medalcode)
- Proyecto: [BuyScraper](https://github.com/Medalcode/BuyScraper)

## ğŸ™ Agradecimientos

- BeautifulSoup4 por el excelente HTML parsing
- Plotly y Matplotlib por visualizaciones
- Pandas por manipulaciÃ³n de datos
- Comunidad Python por las mejores prÃ¡cticas

---

**â­ Si este proyecto te resultÃ³ Ãºtil, considera darle una estrella en GitHub!**
